{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import FluxKontextPipeline\n",
    "from PIL import Image\n",
    "import helpers.drawing as drawing\n",
    "import numpy as np\n",
    "import cv2\n",
    "import shutil\n",
    "from rembg import remove\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export HF_HUB_CACHE=./cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "Here, we start with character images, then add a background to it. This makes up the target image.\n",
    "Then we remove the character from the target image. This makes the input base image.\n",
    "We use a canvas with white background, and place the character on it. This makes the reference image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal FluxKontext Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...:   0%|                                                 | 0/7 [00:00<?, ?it/s]\n",
      "Loading checkpoint shards:   0%|                                                      | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████| 3/3 [00:00<00:00, 29.36it/s]\u001b[A\n",
      "Loading pipeline components...:  29%|███████████▋                             | 2/7 [00:00<00:00,  5.39it/s]\n",
      "Loading checkpoint shards:   0%|                                                      | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|███████████████████████                       | 1/2 [00:00<00:00,  6.99it/s]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████| 2/2 [00:00<00:00,  7.01it/s]\u001b[A\n",
      "Loading pipeline components...:  57%|███████████████████████▍                 | 4/7 [00:00<00:00,  5.46it/s]You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████| 7/7 [00:00<00:00,  7.14it/s]\n"
     ]
    }
   ],
   "source": [
    "pipe = FluxKontextPipeline.from_pretrained(\n",
    "    \"black-forest-labs/FLUX.1-Kontext-dev\", torch_dtype=torch.bfloat16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the subject/character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 14/14 [00:17<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_image(base_scene_path, save_path, prompt = \"Add character to the image.\", width=None, height=None):\n",
    "    if isinstance(base_scene_path, str):\n",
    "        base_scene = Image.open(base_scene_path).convert(\"RGB\")\n",
    "    else:\n",
    "        base_scene = base_scene_path.convert(\"RGB\")\n",
    "\n",
    "    if width is None:\n",
    "        width, height = base_scene.size\n",
    "\n",
    "    seed = torch.Generator().manual_seed(42)\n",
    "\n",
    "    result_img_base = pipe(\n",
    "        prompt=prompt,\n",
    "        image=base_scene,\n",
    "        num_inference_steps=28,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        # generator=seed,\n",
    "        _auto_resize=False,\n",
    "        max_area=width*height\n",
    "    ).images[0]\n",
    "    result_img_base.save(save_path)\n",
    "    return result_img_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_background(\n",
    "    image: Image.Image,\n",
    "    cropped: bool = True,\n",
    "    padding: int = 10\n",
    ") -> Image.Image:\n",
    "    \"\"\"Remove background and optionally crop to content.\"\"\"\n",
    "    # Convert the PIL image to bytes\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, format=\"PNG\")\n",
    "    \n",
    "    # Remove background\n",
    "    output_bytes = remove(buffer.getvalue())\n",
    "    output_image = Image.open(io.BytesIO(output_bytes)).convert(\"RGBA\")\n",
    "    \n",
    "    if cropped:\n",
    "        # Crop to content with padding\n",
    "        alpha = output_image.split()[3]\n",
    "        bbox = alpha.getbbox()\n",
    "        if bbox:\n",
    "            left, upper, right, lower = bbox\n",
    "            width, height = output_image.size\n",
    "\n",
    "            # Apply padding within bounds\n",
    "            left = max(0, left - padding)\n",
    "            upper = max(0, upper - padding)\n",
    "            right = min(width, right + padding)\n",
    "            lower = min(height, lower + padding)\n",
    "\n",
    "            output_image = output_image.crop((left, upper, right, lower))\n",
    "    \n",
    "    return output_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 105\n"
     ]
    }
   ],
   "source": [
    "# Generate character from the prompt\n",
    "prompt_src = \"custom_data/character-spatial/character.txt\"\n",
    "all_prompts = []\n",
    "\n",
    "\n",
    "\n",
    "with open(prompt_src, \"r\") as f:\n",
    "    prompts = f.readlines()\n",
    "\n",
    "for prompt in prompts:\n",
    "    prompt = prompt.strip()\n",
    "    all_prompts.append(prompt)\n",
    "\n",
    "all_prompts = \" \".join(all_prompts).split(\"---\")\n",
    "all_prompts = [prompt.strip() for prompt in all_prompts]\n",
    "\n",
    "print(len(all_prompts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = \"custom_data/character-spatial\"\n",
    "\n",
    "end_dir = os.path.join(src, \"end\")\n",
    "image_extensions = (\".png\", \".jpg\", \".jpeg\", \".webp\")\n",
    "image_paths = [\n",
    "    os.path.join(end_dir, fname)\n",
    "    for fname in os.listdir(end_dir)\n",
    "    if fname.lower().endswith(image_extensions)\n",
    "]\n",
    "image_paths.sort()\n",
    "\n",
    "# Create end, reference and start folders, if it doesnot exists\n",
    "os.makedirs(os.path.join(src, \"end\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(src, \"character\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(src, \"reference\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(src, \"start\"), exist_ok=True)\n",
    "\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Do this only once. Ignore if your dataset is already named properly\n",
    "# Rename all images in end_dir as 000.<ext>, 001.<ext>, etc.\n",
    "for idx, old_path in enumerate(sorted(image_paths)):\n",
    "    ext = os.path.splitext(old_path)[1].lower()\n",
    "    new_name = f\"{idx:03d}{ext}\"\n",
    "    new_path = os.path.join(end_dir, new_name)\n",
    "    shutil.move(old_path, new_path)\n",
    "\n",
    "# Update image_paths to reflect new names\n",
    "image_paths = [\n",
    "    os.path.join(end_dir, fname)\n",
    "    for fname in sorted(os.listdir(end_dir))\n",
    "    if fname.lower().endswith(image_extensions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target from the prompt\n",
    "for i in range(len(all_prompts)):\n",
    "  w = 1392\n",
    "  h = 756\n",
    "  if random.random() < 0.5:\n",
    "    w = 768\n",
    "    h = 768\n",
    "\n",
    "  end_prompt = all_prompts[i]\n",
    "  end_dir = os.path.join(src, \"end\")\n",
    "  end_save_path = os.path.join(end_dir, f\"boy_{i:03d}.png\")\n",
    "  end = generate_image(end_dir, end_save_path, end_prompt, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character image\n",
    "for i in range(len(image_paths)):\n",
    "  image_path = image_paths[i]\n",
    "  file_name = os.path.basename(image_path).split(\".\")[0]\n",
    "  names = file_name.split(\"_\")[:-1]\n",
    "  names = \" \".join(names)\n",
    "  end_prompt = f\"Extract the {names} from the image, in a white background.\"\n",
    "\n",
    "  w = 768\n",
    "  h = 768\n",
    "\n",
    "  end_save_path = image_path.replace(\"end\", \"end\")\n",
    "  end = generate_image(image_path, end_save_path, end_prompt, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For more editing\n",
    "reference_prompt = \"rotate the cup\"\n",
    "\n",
    "generate_image(end, end_save_path, end_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_prompt = \"Remove the boy from the image.\"\n",
    "for i in range(len(image_paths)):\n",
    "  image_path = image_paths[i]\n",
    "  start_save_path = image_path.replace(\"end\", \"start\")\n",
    "  start = generate_image(image_path, start_save_path, start_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end.size, start.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure both images are the same size and mode\n",
    "if start.size != end.size or start.mode != end.mode:\n",
    "    end_resized = end.resize(start.size).convert(start.mode)\n",
    "else:\n",
    "    end_resized = end\n",
    "\n",
    "# Convert to numpy arrays\n",
    "start_np = np.array(start)\n",
    "end_np = np.array(end_resized)\n",
    "\n",
    "# Compute absolute pixel-wise difference\n",
    "diff_np = np.abs(start_np.astype(np.int16) - end_np.astype(np.int16)).astype(np.uint8)\n",
    "\n",
    "# Convert back to PIL Image\n",
    "diff_img = Image.fromarray(diff_np)\n",
    "\n",
    "# Optionally display or save the difference image\n",
    "diff_img.resize((diff_img.size[0]//3, diff_img.size[1]//3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def zip_src_folder(src, zip_path):\n",
    "    \"\"\"\n",
    "    Create a zip archive from the folder specified by src.\n",
    "\n",
    "    Args:\n",
    "        src (str): Path to the source directory to zip.\n",
    "        zip_path (str): Path to the output zip file.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, dirs, files in os.walk(src):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                # Write file to zip, preserving folder structure relative to src\n",
    "                arcname = os.path.relpath(file_path, start=src)\n",
    "                zipf.write(file_path, arcname=arcname)\n",
    "\n",
    "# Example usage:\n",
    "# src = \"path/to/source_folder\"\n",
    "# zip_path = \"output.zip\"\n",
    "# zip_src_folder(src, zip_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[43mimage_paths\u001b[49m[i]\n\u001b[1;32m      2\u001b[0m start_path \u001b[38;5;241m=\u001b[39m image_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m end_path \u001b[38;5;241m=\u001b[39m image_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcharacter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_paths' is not defined"
     ]
    }
   ],
   "source": [
    "image_path = image_paths[i]\n",
    "start_path = image_path.replace(\"end\", \"start\")\n",
    "character_path = image_path.replace(\"end\", \"character\")\n",
    "\n",
    "reference = Image.open(character_path)\n",
    "start = Image.open(start_path)\n",
    "end = Image.open(image_path)\n",
    "\n",
    "s = 2\n",
    "reference = reference.resize((reference.width//s, reference.height//s))\n",
    "start = start.resize((start.width//s, start.height//s))\n",
    "end = end.resize((end.width//s, end.height//s))\n",
    "\n",
    "\n",
    "\n",
    "merged_image = Image.new(\"RGB\", (reference.width + start.width + end.width, start.height))\n",
    "merged_image.paste(reference, (0, 0))\n",
    "merged_image.paste(start, (reference.width, 0))\n",
    "merged_image.paste(end, (reference.width + start.width, 0))\n",
    "\n",
    "merged_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zustpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
