flux_path: "black-forest-labs/FLUX.1-Kontext-dev"
dtype: "bfloat16"
qwen_image_edit_pipe_id: "Qwen/Qwen-Image-Edit"
type: "qwen"


train:
  batch_size: 1
  accumulate_grad_batches: 1
  dataloader_workers: 5
  save_interval: 500
  sample_interval: 100
  max_steps: -1
  gradient_checkpointing: false
  save_path: "runs"

  resume_training_from_last_checkpoint: true
  # Ignored if resume_training_from_last_checkpoint = true. 
  # Ignored if path does not exist.
  resume_training_from_checkpoint_path: "runs/20250127-114531/ckpt/1000"

  dataset:
    src: "data/character-spatial"
    reference_delta: [1, 0, 0]
    spatial: true
    
    drop_text_prob: 0.1

  sample:
    - prompt: "Add the character to the image"
      init_image: "assets/scene_01.png"
      reference_image: "assets/spatial_reference_scene_01_boy_01.png"

    - prompt: "Add the character to the image"
      init_image: "assets/scene_01.png"
      reference_image: "assets/spatial_reference_scene_01_boy_02.png"

    - prompt: "Add the character to the image"
      init_image: "assets/scene_02.png"
      reference_image: "assets/spatial_reference_scene_02_boy_01.png"

    - prompt: "Add the character to the image"
      init_image: "assets/scene_02.png"
      reference_image: "assets/spatial_reference_scene_02_boy_02.png"

  wandb:
    project: "OminiKontextControl"

  lora_config:
    r: 16
    lora_alpha: 16
    init_lora_weights: "gaussian"
    target_modules: ["to_k", "to_q", "to_v", "to_out.0"]

  optimizer:
    type: "Prodigy"
    params:
      lr: 1
      use_bias_correction: true
      safeguard_warmup: true
      weight_decay: 0.01
