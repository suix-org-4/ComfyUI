flux_path: "black-forest-labs/FLUX.1-Kontext-dev"
dtype: "bfloat16"
type: "flux"


train:
  batch_size: 1
  accumulate_grad_batches: 1
  dataloader_workers: 5
  save_interval: 1000
  sample_interval: 100
  max_steps: -1
  gradient_checkpointing: false
  save_path: "runs"

  resume_training_from_last_checkpoint: false
  # Ignored if resume_training_from_last_checkpoint = true. 
  # Ignored if path does not exist.
  resume_training_from_checkpoint_path: "runs/20250127-114531/ckpt/1000"

  dataset:
    src: "data/character"
    reference_delta: [0, 0, 96]
    spatial: false
    
    drop_text_prob: 0.1

  sample:
    - prompt: "Add the character to the image"
      init_image: "assets/scene_01.png"
      reference_image: "assets/boy_reference_512.png"
      
    - prompt: "Add the character to the image"
      init_image: "assets/scene_02.png"
      reference_image: "assets/boy_reference_512.png"

  wandb:
    project: "OminiKontextControl"

  lora_config:
    r: 16
    lora_alpha: 16
    init_lora_weights: "gaussian"
    target_modules: "(.*x_embedder|.*transformer_blocks\\.[0-9]+\\.(norm|norm1)\\.linear|.*transformer_blocks\\.[0-9]+\\.attn\\.(to_k|to_q|to_v|to_add_out)|.*transformer_blocks\\.[0-9]+\\.attn\\.to_out\\.0|.*single_transformer_blocks\\.[0-9]+\\.attn\\.to_out|.*single_transformer_blocks\\.[0-9]+\\.(proj_mlp|proj_out)|.*(?<!single_)transformer_blocks\\.[0-9]+\\.ff\\.net\\.2|.*(?<!single_)transformer_blocks\\.[0-9]+\\.ff\\.net\\.0\\.proj|.*(?<!single_)transformer_blocks\\.[0-9]+\\.norm1_context\\.linear|.*(?<!single_)transformer_blocks\\.[0-9]+\\.ff_context\\.net\\.0\\.proj|.*(?<!single_)transformer_blocks\\.[0-9]+\\.ff_context\\.net\\.2|.*(?<!single_)transformer_blocks\\.[0-9]+\\.attn\\.(to_add_out|add_k_proj|add_q_proj|add_v_proj))"

  optimizer:
    type: "Prodigy"
    params:
      lr: 1
      use_bias_correction: true
      safeguard_warmup: true
      weight_decay: 0.01
