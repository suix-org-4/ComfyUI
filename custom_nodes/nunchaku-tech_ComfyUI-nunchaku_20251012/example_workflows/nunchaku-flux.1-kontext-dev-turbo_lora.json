{
  "id": "01ecd06d-0e30-419c-91d1-748e7d611cf0",
  "revision": 0,
  "last_node_id": 26,
  "last_link_id": 20,
  "nodes": [
    {
      "id": 1,
      "type": "VAELoader",
      "pos": [
        527.7552490234375,
        413.0078430175781
      ],
      "size": [
        337.76861572265625,
        58
      ],
      "flags": {},
      "order": 0,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "VAE",
          "type": "VAE",
          "links": [
            5,
            7
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAELoader",
        "models": [
          {
            "name": "ae.safetensors",
            "url": "https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/resolve/main/split_files/vae/ae.safetensors",
            "directory": "vae"
          }
        ]
      },
      "widgets_values": [
        "ae.safetensors"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 2,
      "type": "DualCLIPLoader",
      "pos": [
        527.7552490234375,
        233.0077362060547
      ],
      "size": [
        337.76861572265625,
        130
      ],
      "flags": {},
      "order": 1,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "CLIP",
          "type": "CLIP",
          "links": [
            18
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "DualCLIPLoader",
        "models": [
          {
            "name": "clip_l.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/clip_l.safetensors",
            "directory": "text_encoders"
          },
          {
            "name": "t5xxl_fp8_e4m3fn_scaled.safetensors",
            "url": "https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors",
            "directory": "text_encoders"
          }
        ]
      },
      "widgets_values": [
        "clip_l.safetensors",
        "t5xxl_fp8_e4m3fn_scaled.safetensors",
        "flux",
        "default"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 3,
      "type": "ConditioningZeroOut",
      "pos": [
        1175.2686767578125,
        229.18930053710938
      ],
      "size": [
        240,
        26
      ],
      "flags": {
        "collapsed": false
      },
      "order": 17,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 1
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            16
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39",
        "Node name for S&R": "ConditioningZeroOut"
      }
    },
    {
      "id": 4,
      "type": "PreviewImage",
      "pos": [
        1245.2686767578125,
        889.1893310546875
      ],
      "size": [
        420,
        310
      ],
      "flags": {},
      "order": 19,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 2
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "PreviewImage"
      },
      "widgets_values": []
    },
    {
      "id": 5,
      "type": "SaveImage",
      "pos": [
        1685.2686767578125,
        539.1893310546875
      ],
      "size": [
        650,
        660
      ],
      "flags": {},
      "order": 25,
      "mode": 0,
      "inputs": [
        {
          "name": "images",
          "type": "IMAGE",
          "link": 3
        }
      ],
      "outputs": [],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39"
      },
      "widgets_values": [
        "ComfyUI"
      ]
    },
    {
      "id": 6,
      "type": "LoadImageOutput",
      "pos": [
        875.2686157226562,
        799.1893310546875
      ],
      "size": [
        320,
        374
      ],
      "flags": {},
      "order": 2,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            10
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "LoadImageOutput"
      },
      "widgets_values": [
        "WechatIMG4530.jpg [output]",
        false,
        "refresh",
        "image"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 7,
      "type": "VAEDecode",
      "pos": [
        1455.2686767578125,
        379.1893005371094
      ],
      "size": [
        190,
        46
      ],
      "flags": {
        "collapsed": false
      },
      "order": 24,
      "mode": 0,
      "inputs": [
        {
          "name": "samples",
          "type": "LATENT",
          "link": 4
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 5
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "slot_index": 0,
          "links": [
            3
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "VAEDecode"
      }
    },
    {
      "id": 8,
      "type": "VAEEncode",
      "pos": [
        905.2686157226562,
        429.1893005371094
      ],
      "size": [
        240,
        50
      ],
      "flags": {
        "collapsed": false
      },
      "order": 20,
      "mode": 0,
      "inputs": [
        {
          "name": "pixels",
          "type": "IMAGE",
          "link": 6
        },
        {
          "name": "vae",
          "type": "VAE",
          "link": 7
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": [
            13,
            17
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.39",
        "Node name for S&R": "VAEEncode"
      }
    },
    {
      "id": 9,
      "type": "FluxKontextImageScale",
      "pos": [
        875.2686157226562,
        599.1893310546875
      ],
      "size": [
        270,
        30
      ],
      "flags": {
        "collapsed": false
      },
      "order": 18,
      "mode": 0,
      "inputs": [
        {
          "name": "image",
          "type": "IMAGE",
          "link": 8
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            2,
            6
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxKontextImageScale"
      }
    },
    {
      "id": 10,
      "type": "MarkdownNote",
      "pos": [
        875.2686157226562,
        669.1893310546875
      ],
      "size": [
        320,
        88
      ],
      "flags": {},
      "order": 3,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About Flux Kontext Edit",
      "properties": {},
      "widgets_values": [
        "[English] Use Ctrl + B to enable multipule image input.\n\n[中文] 使用 **Ctrl + B** 来启用多张图片输入"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 11,
      "type": "ImageStitch",
      "pos": [
        535.2686157226562,
        599.1893310546875
      ],
      "size": [
        270,
        150
      ],
      "flags": {},
      "order": 16,
      "mode": 0,
      "inputs": [
        {
          "name": "image1",
          "type": "IMAGE",
          "link": 9
        },
        {
          "name": "image2",
          "shape": 7,
          "type": "IMAGE",
          "link": 10
        }
      ],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            8
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "ImageStitch"
      },
      "widgets_values": [
        "right",
        true,
        0,
        "white"
      ]
    },
    {
      "id": 12,
      "type": "FluxGuidance",
      "pos": [
        1175.2686767578125,
        119.1893081665039
      ],
      "size": [
        240,
        58
      ],
      "flags": {
        "collapsed": false
      },
      "order": 22,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 11
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            15
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "FluxGuidance"
      },
      "widgets_values": [
        2.5
      ]
    },
    {
      "id": 13,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        519.1893310546875
      ],
      "size": [
        510,
        170
      ],
      "flags": {},
      "order": 4,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About VRAM",
      "properties": {},
      "widgets_values": [
        "For reference:\n- **fp8_scaled**: Requires about 20GB of VRAM.\n- **Original**: Requires about 32GB of VRAM.\n\n---\n\n供参考：\n-  **fp8_scaled** :  大概需要 20GB 左右 VRAM \n- **原始权重**:  原始权重，大概需要 32GB 左右 VRAM \n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 14,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        739.1893310546875
      ],
      "size": [
        510,
        170
      ],
      "flags": {},
      "order": 5,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Flux Kontext Prompt Techniques",
      "properties": {},
      "widgets_values": [
        "\n## Flux Kontext Prompt Techniques\n\n### 1. Basic Modifications\n- Simple and direct: `\"Change the car color to red\"`\n- Maintain style: `\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. Style Transfer\n**Principles:**\n- Clearly name style: `\"Transform to Bauhaus art style\"`\n- Describe characteristics: `\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- Preserve composition: `\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. Character Consistency\n**Framework:**\n- Specific description: `\"The woman with short black hair\"` instead of \"she\"\n- Preserve features: `\"while maintaining the same facial features, hairstyle, and expression\"`\n- Step-by-step modifications: Change background first, then actions\n\n### 4. Text Editing\n- Use quotes: `\"Replace 'joy' with 'BFL'\"`\n- Maintain format: `\"Replace text while maintaining the same font style\"`\n\n## Common Problem Solutions\n\n### Character Changes Too Much\n❌ Wrong: `\"Transform the person into a Viking\"`\n✅ Correct: `\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### Composition Position Changes\n❌ Wrong: `\"Put him on a beach\"`\n✅ Correct: `\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### Style Application Inaccuracy\n❌ Wrong: `\"Make it a sketch\"`\n✅ Correct: `\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## Core Principles\n\n1. **Be Specific and Clear** - Use precise descriptions, avoid vague terms\n2. **Step-by-step Editing** - Break complex modifications into multiple simple steps\n3. **Explicit Preservation** - State what should remain unchanged\n4. **Verb Selection** - Use \"change\", \"replace\" rather than \"transform\"\n\n## Best Practice Templates\n\n**Object Modification:**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**Style Transfer:**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**Background Replacement:**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**Text Editing:**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **Remember:** The more specific, the better. Kontext excels at understanding detailed instructions and maintaining consistency. "
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 15,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        959.1893310546875
      ],
      "size": [
        510,
        180
      ],
      "flags": {},
      "order": 6,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Flux Kontext 提示词技巧",
      "properties": {},
      "widgets_values": [
        "\n## Flux Kontext 提示词技巧\n\n使用英文\n\n### 1. 基础修改\n- 简单直接：`\"Change the car color to red\"`\n- 保持风格：`\"Change to daytime while maintaining the same style of the painting\"`\n\n### 2. 风格转换\n**原则：**\n- 明确命名风格：`\"Transform to Bauhaus art style\"`\n- 描述特征：`\"Transform to oil painting with visible brushstrokes, thick paint texture\"`\n- 保留构图：`\"Change to Bauhaus style while maintaining the original composition\"`\n\n### 3. 角色一致性\n**框架：**\n- 具体描述：`\"The woman with short black hair\"`而非`\"她\"`\n- 保留特征：`\"while maintaining the same facial features, hairstyle, and expression\"`\n- 分步修改：先改背景，再改动作\n\n### 4. 文本编辑\n- 使用引号：`\"Replace 'joy' with 'BFL'\"`\n- 保持格式：`\"Replace text while maintaining the same font style\"`\n\n## 常见问题解决\n\n### 角色变化过大\n❌ 错误：`\"Transform the person into a Viking\"`\n✅ 正确：`\"Change the clothes to be a viking warrior while preserving facial features\"`\n\n### 构图位置改变\n❌ 错误：`\"Put him on a beach\"`\n✅ 正确：`\"Change the background to a beach while keeping the person in the exact same position, scale, and pose\"`\n\n### 风格应用不准确\n❌ 错误：`\"Make it a sketch\"`\n✅ 正确：`\"Convert to pencil sketch with natural graphite lines, cross-hatching, and visible paper texture\"`\n\n## 核心原则\n\n1. **具体明确** - 使用精确描述，避免模糊词汇\n2. **分步编辑** - 复杂修改分为多个简单步骤\n3. **明确保留** - 说明哪些要保持不变\n4. **动词选择** - 用\"更改\"、\"替换\"而非\"转换\"\n\n## 最佳实践模板\n\n**对象修改：**\n`\"Change [object] to [new state], keep [content to preserve] unchanged\"`\n\n**风格转换：**\n`\"Transform to [specific style], while maintaining [composition/character/other] unchanged\"`\n\n**背景替换：**\n`\"Change the background to [new background], keep the subject in the exact same position and pose\"`\n\n**文本编辑：**\n`\"Replace '[original text]' with '[new text]', maintain the same font style\"`\n\n> **记住：** 越具体越好，Kontext 擅长理解详细指令并保持一致性。"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 16,
      "type": "MarkdownNote",
      "pos": [
        -34.73136520385742,
        69.1893081665039
      ],
      "size": [
        510,
        400
      ],
      "flags": {},
      "order": 7,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "Model links",
      "properties": {},
      "widgets_values": [
        "[tutorial](http://docs.comfy.org/tutorials/flux/flux-1-kontext-dev) | [教程](http://docs.comfy.org/zh-CN/tutorials/flux/flux-1-kontext-dev)\n\n**diffusion model**\n\n- [flux1-dev-kontext_fp8_scaled.safetensors](https://huggingface.co/Comfy-Org/flux1-kontext-dev_ComfyUI/resolve/main/split_files/diffusion_models/flux1-dev-kontext_fp8_scaled.safetensors)\n\n**vae**\n\n- [ae.safetensors](https://huggingface.co/Comfy-Org/Lumina_Image_2.0_Repackaged/blob/main/split_files/vae/ae.safetensors)\n\n**text encoder**\n\n- [clip_l.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/blob/main/clip_l.safetensors)\n- [t5xxl_fp16.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp16.safetensors) or [t5xxl_fp8_e4m3fn_scaled.safetensors](https://huggingface.co/comfyanonymous/flux_text_encoders/resolve/main/t5xxl_fp8_e4m3fn_scaled.safetensors)\n\nModel Storage Location\n\n```\n📂 ComfyUI/\n├── 📂 models/\n│   ├── 📂 diffusion_models/\n│   │   └── flux1-dev-kontext_fp8_scaled.safetensors\n│   ├── 📂 vae/\n│   │   └── ae.safetensor\n│   └── 📂 text_encoders/\n│       ├── clip_l.safetensors\n│       └── t5xxl_fp16.safetensors 或者 t5xxl_fp8_e4m3fn_scaled.safetensors\n```\n"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 17,
      "type": "ReferenceLatent",
      "pos": [
        935.2686157226562,
        169.18930053710938
      ],
      "size": [
        197.712890625,
        46
      ],
      "flags": {},
      "order": 21,
      "mode": 0,
      "inputs": [
        {
          "name": "conditioning",
          "type": "CONDITIONING",
          "link": 12
        },
        {
          "name": "latent",
          "shape": 7,
          "type": "LATENT",
          "link": 13
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "links": [
            11
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "ReferenceLatent"
      }
    },
    {
      "id": 18,
      "type": "MarkdownNote",
      "pos": [
        895.2686157226562,
        -120.8106918334961
      ],
      "size": [
        540,
        150
      ],
      "flags": {},
      "order": 8,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "About multiple images reference",
      "properties": {},
      "widgets_values": [
        "[English] In addition to using **Image Stitch** to combine two images at a time, you can also encode individual images, then concatenate multiple latent conditions using the **ReferenceLatent** node, thus achieving the purpose of referencing multiple images. You can use the **EmptySD3LatentImage** node on the right to connect to **KSamper** and customize the size of the **latent_image**.\n\n[中文] 除了使用 **Image Stitch** 将两个两个图像拼合之外，你同样可以将单独的图像 encode 之后，将多个 latent 条件使用 **ReferenceLatent** 节点串联，从而实现多张图像参考的目的。可以使用右边的 **EmptySD3LatentImage** 节点连接到 **KSamper**来自定义 **latent_image** 的尺寸"
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 19,
      "type": "EmptySD3LatentImage",
      "pos": [
        1455.2686767578125,
        -110.8106918334961
      ],
      "size": [
        310,
        106
      ],
      "flags": {},
      "order": 9,
      "mode": 4,
      "inputs": [],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.41",
        "Node name for S&R": "EmptySD3LatentImage"
      },
      "widgets_values": [
        1024,
        1024,
        1
      ]
    },
    {
      "id": 21,
      "type": "MarkdownNote",
      "pos": [
        -504.7313537597656,
        69.1893081665039
      ],
      "size": [
        450,
        450
      ],
      "flags": {},
      "order": 10,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "title": "✨ New ComfyUI feature for Flux.1 Kontext Dev",
      "properties": {},
      "widgets_values": [
        "[English]\nWe have added an **Edit** button to the **Selection Toolbox** of the node for **FLUX.1 Kontext Image Edit** support. When clicked, it quickly adds a **FLUX.1 Kontext Image Edit** group node to the Latent output of your current workflow. This enables an interactive editing experience where you can:\n\n- Create multiple editing iterations, each preserved as a separate node\n- Easily branch off from any previous edit point to explore different creative directions\n- Return to any earlier version and start a new editing branch\n- Modify parameters in earlier nodes and automatically update all downstream edits\n- Execute or re-execute any branch of edits at any time\n- When you want to maintain the effect of the corresponding branch, please set the seed of the corresponding group node to fixed.\n\n\nThis workflow mirrors the iterative nature of LLM conversations, but with the added advantage of visual editing and the ability to maintain multiple parallel editing paths.\n\n---\n\n[中文]\n我们为 **FLUX.1 Kontext Image Edit** 的相关支持在节点的**选择工具箱**上新增了一个**编辑**按钮。点击后，系统会在当前工作流的 Latent 输出上快速添加一个 **FLUX.1 Kontext Image Edit** 的组节点。这种设计带来了灵活的交互式编辑体验：\n\n- 创建多个编辑迭代，每次编辑都会保存为独立节点\n- 可以从任何之前的编辑点分支出新的创作方向\n- 随时返回到早期版本并开始新的编辑分支\n- 修改早期节点的参数，自动更新所有下游编辑\n- 可以随时执行或重新执行任何编辑分支\n- 想要固定对应分支效果时，请将对应的 seed 设置为 fixed\n\n这种工作流程类似于 LLM 对话的迭代特性，但增加了视觉编辑的优势，并能够维护多个并行的编辑路径。"
      ],
      "color": "#322",
      "bgcolor": "#533"
    },
    {
      "id": 25,
      "type": "CLIPTextEncode",
      "pos": [
        1255.2686767578125,
        589.1893310546875
      ],
      "size": [
        400,
        220
      ],
      "flags": {},
      "order": 14,
      "mode": 0,
      "inputs": [
        {
          "name": "clip",
          "type": "CLIP",
          "link": 18
        }
      ],
      "outputs": [
        {
          "name": "CONDITIONING",
          "type": "CONDITIONING",
          "slot_index": 0,
          "links": [
            1,
            12
          ]
        }
      ],
      "title": "CLIP Text Encode (Positive Prompt)",
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "CLIPTextEncode"
      },
      "widgets_values": [
        "Make Pikachu hold a sign that says 'Nunchaku is awesome', yarn art style, detailed, vibrant colors"
      ],
      "color": "#232",
      "bgcolor": "#353"
    },
    {
      "id": 22,
      "type": "NunchakuFluxDiTLoader",
      "pos": [
        558.5625,
        -142.81434631347656
      ],
      "size": [
        275.7613220214844,
        202
      ],
      "flags": {},
      "order": 11,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            19
          ]
        }
      ],
      "properties": {
        "cnr_id": "ComfyUI-nunchaku",
        "ver": "3b2c771cf2f4e62f97c284bfd8f594482c5f8bc0",
        "Node name for S&R": "NunchakuFluxDiTLoader"
      },
      "widgets_values": [
        "svdq-int4_r32-flux.1-kontext-dev.safetensors",
        0,
        "nunchaku-fp16",
        "auto",
        0,
        "bfloat16",
        "enabled"
      ]
    },
    {
      "id": 26,
      "type": "NunchakuFluxLoraLoader",
      "pos": [
        545.2327880859375,
        114.53527069091797
      ],
      "size": [
        300.6851501464844,
        82
      ],
      "flags": {},
      "order": 15,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 19
        }
      ],
      "outputs": [
        {
          "name": "MODEL",
          "type": "MODEL",
          "links": [
            20
          ]
        }
      ],
      "properties": {
        "cnr_id": "ComfyUI-nunchaku",
        "ver": "3b2c771cf2f4e62f97c284bfd8f594482c5f8bc0",
        "Node name for S&R": "NunchakuFluxLoraLoader"
      },
      "widgets_values": [
        "flux.1-turbo-alpha.safetensors",
        1
      ]
    },
    {
      "id": 20,
      "type": "KSampler",
      "pos": [
        1455.2686767578125,
        69.1893081665039
      ],
      "size": [
        320,
        262
      ],
      "flags": {},
      "order": 23,
      "mode": 0,
      "inputs": [
        {
          "name": "model",
          "type": "MODEL",
          "link": 20
        },
        {
          "name": "positive",
          "type": "CONDITIONING",
          "link": 15
        },
        {
          "name": "negative",
          "type": "CONDITIONING",
          "link": 16
        },
        {
          "name": "latent_image",
          "type": "LATENT",
          "link": 17
        }
      ],
      "outputs": [
        {
          "name": "LATENT",
          "type": "LATENT",
          "slot_index": 0,
          "links": [
            4
          ]
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.38",
        "Node name for S&R": "KSampler"
      },
      "widgets_values": [
        250965779323742,
        "randomize",
        8,
        1,
        "euler",
        "simple",
        1
      ]
    },
    {
      "id": 23,
      "type": "MarkdownNote",
      "pos": [
        139.17037963867188,
        -144.5917205810547
      ],
      "size": [
        390.7500915527344,
        159.8812713623047
      ],
      "flags": {},
      "order": 12,
      "mode": 0,
      "inputs": [],
      "outputs": [],
      "properties": {},
      "widgets_values": [
        "Download the model from [HuggingFace](https://huggingface.co/mit-han-lab/nunchaku-flux.1-kontext-dev) or [ModelScope](https://modelscope.cn/models/Lmxyy1999/nunchaku-flux.1-kontext-dev).\n\n- Use the **FP4** variant if you're running on **Blackwell (50-series) GPUs**.\n- Otherwise, choose the **INT4** version for better compatibility.\n\nYou can adjust the `cache_threshold` parameter to balance **image quality** and **inference speed**. A value of `0.12` typically offers a good trade-off.\n\nEnable `cpu_offload` to **save GPU memory** if you're running into memory limits.\n\nThe Turbo LoRA can be found at this [HuggingFace Repo](https://huggingface.co/alimama-creative/FLUX.1-Turbo-Alpha)."
      ],
      "color": "#432",
      "bgcolor": "#653"
    },
    {
      "id": 24,
      "type": "LoadImageOutput",
      "pos": [
        535.2686157226562,
        799.1893310546875
      ],
      "size": [
        320,
        374
      ],
      "flags": {},
      "order": 13,
      "mode": 0,
      "inputs": [],
      "outputs": [
        {
          "name": "IMAGE",
          "type": "IMAGE",
          "links": [
            9
          ]
        },
        {
          "name": "MASK",
          "type": "MASK",
          "links": null
        }
      ],
      "properties": {
        "cnr_id": "comfy-core",
        "ver": "0.3.40",
        "Node name for S&R": "LoadImageOutput"
      },
      "widgets_values": [
        "yarn-art-pikachu.png [output]",
        false,
        "refresh",
        "image"
      ],
      "color": "#322",
      "bgcolor": "#533"
    }
  ],
  "links": [
    [
      1,
      25,
      0,
      3,
      0,
      "CONDITIONING"
    ],
    [
      2,
      9,
      0,
      4,
      0,
      "IMAGE"
    ],
    [
      3,
      7,
      0,
      5,
      0,
      "IMAGE"
    ],
    [
      4,
      20,
      0,
      7,
      0,
      "LATENT"
    ],
    [
      5,
      1,
      0,
      7,
      1,
      "VAE"
    ],
    [
      6,
      9,
      0,
      8,
      0,
      "IMAGE"
    ],
    [
      7,
      1,
      0,
      8,
      1,
      "VAE"
    ],
    [
      8,
      11,
      0,
      9,
      0,
      "IMAGE"
    ],
    [
      9,
      24,
      0,
      11,
      0,
      "IMAGE"
    ],
    [
      10,
      6,
      0,
      11,
      1,
      "IMAGE"
    ],
    [
      11,
      17,
      0,
      12,
      0,
      "CONDITIONING"
    ],
    [
      12,
      25,
      0,
      17,
      0,
      "CONDITIONING"
    ],
    [
      13,
      8,
      0,
      17,
      1,
      "LATENT"
    ],
    [
      15,
      12,
      0,
      20,
      1,
      "CONDITIONING"
    ],
    [
      16,
      3,
      0,
      20,
      2,
      "CONDITIONING"
    ],
    [
      17,
      8,
      0,
      20,
      3,
      "LATENT"
    ],
    [
      18,
      2,
      0,
      25,
      0,
      "CLIP"
    ],
    [
      19,
      22,
      0,
      26,
      0,
      "MODEL"
    ],
    [
      20,
      26,
      0,
      20,
      0,
      "MODEL"
    ]
  ],
  "groups": [
    {
      "id": 1,
      "title": "Step 2 - Upload images",
      "bounding": [
        515.2686157226562,
        509.1893005371094,
        700,
        680
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 2,
      "title": "Step 3 - Prompt",
      "bounding": [
        1235.2686767578125,
        509.1893005371094,
        430,
        330
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    },
    {
      "id": 3,
      "title": "Conditioning",
      "bounding": [
        895.2686157226562,
        39.18930435180664,
        540,
        250
      ],
      "color": "#3f789e",
      "font_size": 24,
      "flags": {}
    }
  ],
  "config": {},
  "extra": {
    "ds": {
      "scale": 0.7400249944258639,
      "offset": [
        415.32938004324257,
        185.38596457319667
      ]
    },
    "frontendVersion": "1.23.4"
  },
  "version": 0.4
}
